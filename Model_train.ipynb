{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92b87ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/miniconda3/envs/ft/lib/python3.10/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmpzxzrvchq as temporary training directory\n",
      "Reading training dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/miniconda3/envs/ft/lib/python3.10/site-packages/tensorflow_decision_forests/keras/core_inference.py:873: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features_dataframe = dataframe.drop(label, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f944c4e9090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function CoreModel._consumes_training_examples_until_eof at 0x7f944c4e9090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset read in 0:00:03.635724. Found 1296675 examples.\n",
      "Training model...\n",
      "Model trained in 0:03:39.399606\n",
      "Compiling model...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f924c783010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO kernel.cc:1176] Loading model from path /tmp/tmpzxzrvchq/model/ with prefix a19da395d3d34c86\n",
      "[INFO abstract_model.cc:1248] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n",
      "[INFO kernel.cc:1022] Use fast generic engine\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x7f924c783010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7f924c780dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function InferenceCoreModel.yggdrasil_model_path_tensor at 0x7f924c780dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (9):\n",
      "\tamt\n",
      "\tcategory\n",
      "\tcity\n",
      "\tdob\n",
      "\tfirst\n",
      "\tlast\n",
      "\tstate\n",
      "\ttrans_date_trans_time\n",
      "\tzip\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: MEAN_MIN_DEPTH:\n",
      "    1. \"trans_date_trans_time\"  4.897434 ################\n",
      "    2.               \"__LABEL\"  4.897434 ################\n",
      "    3.                   \"zip\"  4.848877 ###############\n",
      "    4.                 \"first\"  4.314785 #############\n",
      "    5.                  \"last\"  4.012833 ############\n",
      "    6.              \"category\"  3.889433 ############\n",
      "    7.                  \"city\"  3.639885 ###########\n",
      "    8.                 \"state\"  3.593390 ##########\n",
      "    9.                   \"dob\"  2.889711 ########\n",
      "   10.                   \"amt\"  0.795168 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1.      \"dob\" 101.000000 ################\n",
      "    2.      \"amt\" 70.000000 ###########\n",
      "    3.     \"city\" 50.000000 #######\n",
      "    4.     \"last\" 37.000000 #####\n",
      "    5.    \"first\" 19.000000 ##\n",
      "    6.    \"state\" 13.000000 #\n",
      "    7. \"category\"  1.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.      \"amt\" 3039.000000 ################\n",
      "    2.    \"state\" 1697.000000 ########\n",
      "    3. \"category\" 892.000000 ####\n",
      "    4.      \"dob\" 723.000000 ###\n",
      "    5.     \"city\" 581.000000 ##\n",
      "    6.     \"last\" 520.000000 ##\n",
      "    7.    \"first\" 462.000000 ##\n",
      "    8.      \"zip\" 33.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1. \"category\" 5593.047376 ################\n",
      "    2.      \"amt\" 3923.105652 ###########\n",
      "    3.    \"state\" 1533.764351 ####\n",
      "    4.      \"dob\" 485.569897 #\n",
      "    5.     \"city\" 410.582839 #\n",
      "    6.    \"first\" 408.819943 #\n",
      "    7.     \"last\" 375.102239 #\n",
      "    8.      \"zip\"  6.215095 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 0.0178765\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 291\n",
      "Total number of nodes: 16185\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 291 Average: 55.6186 StdDev: 7.21221\n",
      "Min: 33 Max: 63 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 33, 34) 13   4.47%   4.47% ##\n",
      "[ 34, 36)  0   0.00%   4.47%\n",
      "[ 36, 37)  0   0.00%   4.47%\n",
      "[ 37, 39)  1   0.34%   4.81%\n",
      "[ 39, 40)  0   0.00%   4.81%\n",
      "[ 40, 42)  4   1.37%   6.19% #\n",
      "[ 42, 43)  0   0.00%   6.19%\n",
      "[ 43, 45)  1   0.34%   6.53%\n",
      "[ 45, 46)  4   1.37%   7.90% #\n",
      "[ 46, 48) 10   3.44%  11.34% ##\n",
      "[ 48, 50) 13   4.47%  15.81% ##\n",
      "[ 50, 51)  0   0.00%  15.81%\n",
      "[ 51, 53) 21   7.22%  23.02% ####\n",
      "[ 53, 54) 31  10.65%  33.68% #####\n",
      "[ 54, 56) 26   8.93%  42.61% ####\n",
      "[ 56, 57)  0   0.00%  42.61%\n",
      "[ 57, 59) 40  13.75%  56.36% #######\n",
      "[ 59, 60) 31  10.65%  67.01% #####\n",
      "[ 60, 62) 38  13.06%  80.07% #######\n",
      "[ 62, 63] 58  19.93% 100.00% ##########\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 8238 Average: 4.90774 StdDev: 0.378771\n",
      "Min: 1 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 1, 2)   13   0.16%   0.16%\n",
      "[ 2, 3)    3   0.04%   0.19%\n",
      "[ 3, 4)  159   1.93%   2.12%\n",
      "[ 4, 5)  381   4.62%   6.75%\n",
      "[ 5, 5] 7682  93.25% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 8238 Average: 41222.4 StdDev: 140983\n",
      "Min: 5 Max: 1164812 Ignored: 0\n",
      "----------------------------------------------\n",
      "[       5,   58245) 7274  88.30%  88.30% ##########\n",
      "[   58245,  116485)  224   2.72%  91.02%\n",
      "[  116485,  174726)  156   1.89%  92.91%\n",
      "[  174726,  232966)   97   1.18%  94.09%\n",
      "[  232966,  291207)   67   0.81%  94.90%\n",
      "[  291207,  349447)   46   0.56%  95.46%\n",
      "[  349447,  407687)   14   0.17%  95.63%\n",
      "[  407687,  465928)   12   0.15%  95.78%\n",
      "[  465928,  524168)   26   0.32%  96.09%\n",
      "[  524168,  582409)  113   1.37%  97.46%\n",
      "[  582409,  640649)  151   1.83%  99.30%\n",
      "[  640649,  698889)   19   0.23%  99.53%\n",
      "[  698889,  757130)    1   0.01%  99.54%\n",
      "[  757130,  815370)    0   0.00%  99.54%\n",
      "[  815370,  873611)    1   0.01%  99.55%\n",
      "[  873611,  931851)    2   0.02%  99.58%\n",
      "[  931851,  990091)    0   0.00%  99.58%\n",
      "[  990091, 1.04833e+06)    0   0.00%  99.58%\n",
      "[ 1.04833e+06, 1.10657e+06)    0   0.00%  99.58%\n",
      "[ 1.10657e+06, 1.16481e+06]   35   0.42% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t3039 : amt [NUMERICAL]\n",
      "\t1697 : state [CATEGORICAL]\n",
      "\t892 : category [CATEGORICAL]\n",
      "\t723 : dob [CATEGORICAL]\n",
      "\t581 : city [CATEGORICAL]\n",
      "\t520 : last [CATEGORICAL]\n",
      "\t462 : first [CATEGORICAL]\n",
      "\t33 : zip [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t101 : dob [CATEGORICAL]\n",
      "\t70 : amt [NUMERICAL]\n",
      "\t50 : city [CATEGORICAL]\n",
      "\t37 : last [CATEGORICAL]\n",
      "\t19 : first [CATEGORICAL]\n",
      "\t13 : state [CATEGORICAL]\n",
      "\t1 : category [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t536 : amt [NUMERICAL]\n",
      "\t113 : dob [CATEGORICAL]\n",
      "\t69 : city [CATEGORICAL]\n",
      "\t56 : category [CATEGORICAL]\n",
      "\t42 : last [CATEGORICAL]\n",
      "\t21 : first [CATEGORICAL]\n",
      "\t17 : state [CATEGORICAL]\n",
      "\t6 : zip [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t1219 : amt [NUMERICAL]\n",
      "\t203 : category [CATEGORICAL]\n",
      "\t171 : dob [CATEGORICAL]\n",
      "\t131 : state [CATEGORICAL]\n",
      "\t128 : city [CATEGORICAL]\n",
      "\t75 : last [CATEGORICAL]\n",
      "\t60 : first [CATEGORICAL]\n",
      "\t8 : zip [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t1916 : amt [NUMERICAL]\n",
      "\t787 : state [CATEGORICAL]\n",
      "\t462 : category [CATEGORICAL]\n",
      "\t321 : dob [CATEGORICAL]\n",
      "\t250 : city [CATEGORICAL]\n",
      "\t187 : last [CATEGORICAL]\n",
      "\t166 : first [CATEGORICAL]\n",
      "\t17 : zip [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t3039 : amt [NUMERICAL]\n",
      "\t1697 : state [CATEGORICAL]\n",
      "\t892 : category [CATEGORICAL]\n",
      "\t723 : dob [CATEGORICAL]\n",
      "\t581 : city [CATEGORICAL]\n",
      "\t520 : last [CATEGORICAL]\n",
      "\t462 : first [CATEGORICAL]\n",
      "\t33 : zip [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t4370 : ContainsBitmapCondition\n",
      "\t3072 : HigherCondition\n",
      "\t505 : ContainsCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t208 : ContainsBitmapCondition\n",
      "\t70 : HigherCondition\n",
      "\t13 : ContainsCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t542 : HigherCondition\n",
      "\t305 : ContainsBitmapCondition\n",
      "\t13 : ContainsCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t1227 : HigherCondition\n",
      "\t748 : ContainsBitmapCondition\n",
      "\t20 : ContainsCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t2043 : ContainsBitmapCondition\n",
      "\t1933 : HigherCondition\n",
      "\t130 : ContainsCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t4370 : ContainsBitmapCondition\n",
      "\t3072 : HigherCondition\n",
      "\t505 : ContainsCondition\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "\n",
    "cols = ['trans_date_trans_time', 'category', 'amt', 'first', 'last', 'city', 'state', 'zip', 'dob', 'is_fraud']\n",
    "# Load the dataset in a Pandas dataframe.\n",
    "train_df = pd.read_csv(\"archive/fraudTrain.csv\", usecols = cols)\n",
    "test_df = pd.read_csv(\"archive/fraudTest.csv\", usecols = cols)\n",
    "\n",
    "# Convert the dataset into a TensorFlow dataset.\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"is_fraud\")\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df, label=\"is_fraud\")\n",
    "\n",
    "# Train the model\n",
    "model = tfdf.keras.GradientBoostedTreesModel()\n",
    "model.fit(train_ds)\n",
    "\n",
    "# Look at the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0b45fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 2s 3ms/step - loss: 0.0000e+00 - accuracy: 0.9972\n",
      "\n",
      "loss: 0.0000\n",
      "accuracy: 0.9972\n"
     ]
    }
   ],
   "source": [
    "model.compile(metrics=[\"accuracy\"])\n",
    "evaluation = model.evaluate(test_ds, return_dict=True)\n",
    "print()\n",
    "\n",
    "for name, value in evaluation.items():\n",
    "  print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22452f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as call_get_leaves while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989de2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
